{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#贝叶斯优化超参数\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\n!pip install ax-platform\nfrom ax.plot.contour import plot_contour\nfrom ax.plot.trace import optimization_trace_single_method\nfrom ax.service.managed_loop import optimize\nfrom ax.utils.notebook.plotting import render\nfrom ax.utils.tutorials.cnn_utils import train, evaluate\nimport pandas as pd\n#import datainfor\nfrom torch.utils.data import Dataset,DataLoader\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nimport pandas as pd\nfrom torch.utils.data import Dataset,DataLoader\nfrom PIL import Image\nimport torch.optim as optim\nfrom sklearn.metrics import accuracy_score,multilabel_confusion_matrix\nfrom torch.optim import lr_scheduler\n#import npmetrics\n#import multi_model512_先验_3 as multi_model_128\n#from src.loss_functions.losses_调整 import AsymmetricLoss,FocalLoss,AsymmetricLossOptimized,Asy1#引入损失函数\n#import index\nfrom torch.backends import cudnn\ncudnn.benchmark = False            # if benchmark=True, deterministic will be False\ncudnn.deterministic = True\nseed=1\ntorch.manual_seed(seed)            # 为CPU设置随机种子\ntorch.cuda.manual_seed(seed)       # 为当前GPU设置随机种子\ntorch.cuda.manual_seed_all(seed)   # 为所有GPU设置随机种子\nimport random\nimport numpy as np\nrandom.seed(seed)\nnp.random.seed(seed)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T04:04:20.622696Z","iopub.execute_input":"2023-03-31T04:04:20.623493Z","iopub.status.idle":"2023-03-31T04:04:31.080852Z","shell.execute_reply.started":"2023-03-31T04:04:20.623452Z","shell.execute_reply":"2023-03-31T04:04:31.079525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Thu Feb 23 16:10:27 2023\n\n@author: lisha\n\"\"\"\nfrom __future__ import print_function, division\n#import torchsummary\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nimport time\nimport os\nimport copy\nimport pandas as pd\nfrom torch.utils.data import Dataset,DataLoader\nfrom PIL import Image\nimport torch.optim as optim\nfrom sklearn.metrics import accuracy_score,multilabel_confusion_matrix\nfrom torch.optim import lr_scheduler\n# npmetrics\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nlamda=0.01\nnum_class=5\n# Transformer Parameters\nd_model=128# Embedding Size,512-1024,128-512\nq_model=256\nd_ff=1024# FeedForward dimension\nn_layers=4  # number of Encoder of Decoder Layer\nn_heads=4  # number of heads in Multi-Head Attention\nd_k = d_v =int(d_model/n_heads) # dimension of K(=Q), V\nbatch_size=50\nnum_fea=3\n\nclass ScaledDotProductAttention(nn.Module):\n    def __init__(self):\n        super(ScaledDotProductAttention, self).__init__()\n\n    def forward(self, Q, K, V):\n        '''\n        Q: [batch_size, n_heads, len_q, d_k]\n        K: [batch_size, n_heads, len_k, d_k]\n        V: [batch_size, n_heads, len_v(=len_k), d_v]\n        attn_mask: [batch_size, n_heads, seq_len, seq_len]\n    \n        '''\n        #print('11')\n        scores = torch.matmul(Q, K.transpose(-1, -2)) / np.sqrt(d_k) \n        #print('scores',scores.size())\n        #将K的最后两个维度进行转置\n        # scores : [batch_size, n_heads, len_q, len_k]\n        attn = nn.Softmax(dim=-1)(scores)\n        #print('attn',attn.size())\n        #attn就是注意力权重\n        context = torch.matmul(attn, V) \n        # [batch_size, n_heads, len_q, d_v]\n        #print('context',context.size())\n        #print('1')\n        return context, attn\n\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self):\n        super(MultiHeadAttention, self).__init__()\n        self.W_Q = nn.Linear(q_model, d_k * n_heads, bias=False)\n        self.W_K = nn.Linear(d_model, d_k * n_heads, bias=False)\n        self.W_V = nn.Linear(d_model, d_v * n_heads, bias=False)\n        self.fc = nn.Linear(n_heads * d_v, d_model, bias=False)\n        self.nor=nn.LayerNorm(d_model)\n    def forward(self, input_Q, input_K, input_V):\n        '''\n        input_Q: [batch_size, len_q, d_model]\n        input_K: [batch_size, len_k, d_model]\n        input_V: [batch_size, len_v(=len_k), d_model]\n        attn_mask: [batch_size, seq_len, seq_len]\n        '''\n       \n        batch_size=input_Q.size(0)\n        #input_Q=input_Q.view(batch_size, -1, d_model)\n        residual=input_K\n        \n        #print('residual',residual.size())\n        # (B, S, D) -proj-> (B, S, D_new) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n        # (B,D) -proj-> (B, D_new) -split-> (B, H, W)\n        #改变输入到合适的形式\n        # Q = self.W_Q(input_Q).view(batch_size, n_heads, d_k)\n        # # # Q: [batch_size, n_heads, len_q, d_k]\n        # K = self.W_K(input_K).view(batch_size, n_heads, d_k)  \n        # # # K: [batch_size, n_heads, len_k, d_k]\n        # V = self.W_V(input_V).view(batch_size, n_heads, d_v)\n        # V: [batch_size, n_heads, len_v(=len_k), d_v]\n        Q = self.W_Q(input_Q).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # Q: [batch_size, n_heads, len_q, d_k]\n        K = self.W_K(input_K).view(batch_size, -1, n_heads, d_k).transpose(1,2)  # K: [batch_size, n_heads, len_k, d_k]\n        V = self.W_V(input_V).view(batch_size, -1, n_heads, d_v).transpose(1,2)  # V: [batch_size, n_heads, len_v(=len_k), d_v]\n        # print('Q:',Q.size())\n        # print('K:',K.size())\n        \n        #attn_mask = attn_mask.unsqueeze(1).repeat(1, n_heads, 1, 1) \n        # attn_mask : [batch_size, n_heads, seq_len, seq_len]\n\n        # context: [batch_size, n_heads, len_q, d_v], attn: [batch_size, n_heads, len_q, len_k]\n        context, attn = ScaledDotProductAttention()(Q, K, V)\n        \n        context = context.transpose(1, 2).reshape(batch_size, -1, n_heads * d_v) \n    \n        # context: [batch_size, len_q, n_heads * d_v]\n        output_ = self.fc(context) # [batch_size, len_q, d_model]\n       \n        #print('attn_output_',output_.size())\n        residual.to(device)\n        output_.to(device)\n        output=self.nor(output_ + residual)\n        #output=nn.LayerNorm(d_model)(output_ + residual)\n        \n        #print('multioutput',(output_ + residual).size())\n        #print('2')\n        return output, attn\n    #返回子层结果和attn\n\n#前向神经网络\nclass PoswiseFeedForwardNet(nn.Module):\n    def __init__(self):\n        super(PoswiseFeedForwardNet, self).__init__()\n        self.fc = nn.Sequential(\n            nn.Linear(d_model, d_ff, bias=False),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(d_ff, d_model, bias=False),\n            #nn.Dropout()\n        )\n        self.nor=nn.LayerNorm(d_model)\n    def forward(self, inputs):\n        '''\n        inputs: [batch_size, seq_len, d_model]\n        '''\n        \n        residual = inputs\n        #print('input',inputs.size())\n        output = self.fc(inputs)\n        #print('FF',output.size())\n        #print('3')\n        return self.nor(output + residual)\n    # [batch_size, seq_len, d_model]\n\nclass EncoderLayer(nn.Module):\n    def __init__(self):\n        super(EncoderLayer, self).__init__()\n        self.enc_self_attn = MultiHeadAttention()\n        self.pos_ffn = PoswiseFeedForwardNet()\n        \n    def forward(self, Q_inputs,enc_inputs):\n        '''\n        enc_inputs: [batch_size, src_len, d_model]\n        enc_self_attn_mask: [batch_size, src_len, src_len]\n        '''\n        \n        Q_inputs.to(device)\n        enc_inputs.to(device)\n        # enc_outputs: [batch_size, src_len, d_model], attn: [batch_size, n_heads, src_len, src_len]\n        enc_outputs, attn = self.enc_self_attn(Q_inputs, enc_inputs, enc_inputs) \n        #print('multiattn输出:',enc_outputs.size())\n        # enc_inputs to same Q,K,V\n        #print('enc_outputs',enc_outputs.is_cuda)\n        enc_outputs = self.pos_ffn(enc_outputs) \n        #print('ff输出:',enc_outputs.size())\n        # enc_outputs: [batch_size, src_len, d_model]\n        #print('EncoderLayer的输出：',enc_outputs.size())\n        #print('4')\n        return enc_outputs, attn\nenc_self_attns=[]\nclass Encoder(nn.Module):\n    def __init__(self):\n        super(Encoder, self).__init__()\n        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n        self.fc=  nn.Sequential(\n            nn.Linear(num_fea*d_model, num_class, bias=False),\n            \n            nn.Sigmoid()\n            #nn.Softmax()\n        )\n        \n    def forward(self,Q_inputs,enc_intputs):\n        '''\n        enc_inputs: [batch_size, src_len]\n        '''\n       \n        #word_emb = self.src_emb(enc_inputs) # [batch_size, src_len, d_model]\n        #pos_emb = self.pos_emb(enc_inputs) # [batch_size, src_len, d_model]\n        #enc_outputs = word_emb + pos_emb\n        #enc_self_attn_mask = get_attn_pad_mask(enc_inputs, enc_inputs) # [batch_size, src_len, src_len]\n        #enc_self_attns = []\n        for layer in self.layers:\n            # enc_outputs: [batch_size, src_len, d_model], enc_self_attn: [batch_size, n_heads, src_len, src_len]\n            enc_intputs, enc_self_attn = layer(Q_inputs,enc_intputs)\n            #print('5')\n            #print('encoder输出',enc_intputs.size())\n            batch_size=enc_intputs.size(0)\n            enc_self_attns.append(enc_self_attn)\n            #enc_intputs数据嵌入后的维数\n        enc_intputs=enc_intputs.view(batch_size,-1)\n        #print('分类前的输出',enc_intputs.size())\n        outputs=self.fc(enc_intputs)\n            \n            \n            \n            #print('outputs',outputs.size())\n        #print('6')\n        return outputs, enc_self_attns\n    \n# def preclass(outputs,lamda): #判断标签\n#     #print('class_outputs',outputs.size())\n#     #print('class_outputs',outputs)\n#     max_value, preds=torch.max(outputs,1)\n    \n#     #print(max_value)\n#     value1=max_value-lamda\n#     #print(value1)   \n#     duibi=value1\n#     for i in range(outputs.shape[1]-1):\n#         duibi=torch.cat([duibi,value1],0)\n#     c=torch.reshape(duibi,(outputs.shape[1],outputs.shape[0]))\n#     d=c.transpose(0,1)\n#     preds=torch.gt(outputs,d)\n#     preds=preds.float()\n#     #print('preds',preds)\n#     return preds\n\ndef preclass(outputs,lamda): #判断标签\n    #print(lamda)\n    A= pd.read_csv(\"/kaggle/input/newdata0330/label_infor.csv\")\n    A=np.array(A) \n    A=A[:,1:]\n    a=A\n    A=torch.from_numpy(A)\n  #找到预测的最大值\n    max_value, location=torch.max(outputs,1)\n    location=location.cpu().numpy()\n    O_=torch.zeros(outputs.shape[0],outputs.shape[1])\n    preds=np.zeros((outputs.shape[0],outputs.shape[1]))\n    for i in range(0,outputs.shape[0]):\n        index=[]\n        a1=[]\n        #preds[i,location[i]]=1\n          #转化概率矩阵\n        O_[i,:]=outputs[i,:]/outputs[i,location[i]]-lamda\n        #location[i]是第i个样本对应的max索引\n        #每个输出概率除以最大输出概率\n        preds1=torch.ge(O_[i,:],A[location[i],:])\n        preds1=preds1.float()\n        #preds1=preds1.numpy()\n        preds[i,:]=preds1\n        a1=a[location[i],:]\n        index=[i for i,x in enumerate(a1) if x==0]\n        preds[i,index]=0\n        preds[i,location[i]]=1\n    #print(preds)\n    preds=torch.from_numpy(preds)\n    return preds\n\n\ndef newacc(preds,labels):\n    #preds=np.cpu().array(preds)\n    copy_preds = preds.clone().detach().cpu()\n    copy_labels = labels.clone().detach().cpu()\n    copy_preds = copy_preds.cpu().numpy()\n    copy_labels= copy_labels.cpu().numpy()\n    # #labels=np.cpu().array(labels)\n    # acc=accuracy_score(copy_labels, copy_preds)\n    # acc_num=acc*copy_labels.shape[0]\n    # acc_num=int(acc_num)\n    acc = np.mean(np.all(np.equal(copy_labels, copy_preds), axis=1).astype(\"float32\"))\n    acc_num=acc*copy_labels.shape[0]\n    acc_num=int(acc_num)\n    #print(acc_num)\n    return acc_num\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndef binary_focal_loss(gamma=2, **_):\n    def func(input, target):\n        assert target.size() == input.size()\n\n        max_val = (-input).clamp(min=0)\n        #clamp(min=0),就相当于relu函数的等效，max(0,wx+b)\n\n        loss = input - input * target + max_val + ((-max_val).exp() + (-input - max_val).exp()).log()\n        invprobs = F.logsigmoid(-input * (target * 2 - 1))\n        #这个\n        loss = (invprobs * gamma).exp() * loss\n        return loss.mean()\n\n    return func\n\n\nclass FocalLoss(nn.Module):\n    # Wraps focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5)\n    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):\n        super(FocalLoss, self).__init__()\n        self.loss_fcn = nn.BCEWithLogitsLoss()  # must be nn.BCEWithLogitsLoss()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = loss_fcn.reduction\n        self.loss_fcn.reduction = 'none'  # required to apply FL to each element\n\n    def forward(self, pred, true):\n        loss = self.loss_fcn(pred, true)\n        # p_t = torch.exp(-loss)\n        # loss *= self.alpha * (1.000001 - p_t) ** self.gamma  # non-zero power for gradient stability\n        \n        # TF implementation https://github.com/tensorflow/addons/blob/v0.7.1/tensorflow_addons/losses/focal_loss.py\n        pred_prob = torch.sigmoid(pred)  # prob from logits\n        p_t = true * pred_prob + (1 - true) * (1 - pred_prob)\n        alpha_factor = true * self.alpha + (1 - true) * (1 - self.alpha)\n        modulating_factor = (1.0 - p_t) ** self.gamma\n        loss *= alpha_factor * modulating_factor\n\n        if self.reduction == 'mean':\n            return loss.mean()\n        elif self.reduction == 'sum':\n            return loss.sum()\n        else:  # 'none'\n            return loss\n\ndef cross_entropy(**_):\n    return torch.nn.BCEWithLogitsLoss()\n\n\ndef get_loss(config):\n    f = globals().get(config.loss.name)\n    return f(**config.loss.params)\n# train_pre=[]\n# train_output=[]\n# train_label=[]\n# test_pre=[]\n# test_output=[]\n# test_label=[]\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T04:04:31.084088Z","iopub.execute_input":"2023-03-31T04:04:31.084548Z","iopub.status.idle":"2023-03-31T04:04:42.963077Z","shell.execute_reply.started":"2023-03-31T04:04:31.084500Z","shell.execute_reply":"2023-03-31T04:04:42.962029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Sun Feb 26 12:15:03 2023\n\n@author: lisha\n\"\"\"\nimport numpy as np\nfrom sklearn.metrics import average_precision_score, f1_score, zero_one_loss,hamming_loss,accuracy_score,multilabel_confusion_matrix\n\nepsilon = 1e-8\n\n\ndef compute_f1(precision, recall):\n    return 2 * precision * recall / (precision + recall + epsilon)\n\n\ndef example_subset_accuracy(gt, predict):\n    ex_equal = np.all(np.equal(gt, predict), axis=1).astype(\"float32\")\n    return np.mean(ex_equal)\n\n\ndef example_accuracy(gt, predict):\n    ex_and = np.sum(np.logical_and(gt, predict), axis=1).astype(\"float32\")\n    ex_or = np.sum(np.logical_or(gt, predict), axis=1).astype(\"float32\")\n    return np.mean((ex_and + epsilon) / (ex_or + epsilon))\n\n\ndef example_precision(gt, predict):\n    ex_and = np.sum(np.logical_and(gt, predict), axis=1).astype(\"float32\")\n    ex_predict = np.sum(predict, axis=1).astype(\"float32\")\n    return np.mean((ex_and + epsilon) / (ex_predict + epsilon))\n\n\ndef example_recall(gt, predict):\n    ex_and = np.sum(np.logical_and(gt, predict), axis=1).astype(\"float32\")\n    ex_gt = np.sum(gt, axis=1).astype(\"float32\")\n    return np.mean((ex_and + epsilon) / (ex_gt + epsilon))\n\n\ndef example_f1(gt, predict):\n    p = example_precision(gt, predict)\n    r = example_recall(gt, predict)\n    return (2 * p * r) / (p + r + epsilon)\n\n\ndef _label_quantity(gt, predict):\n    tp = np.sum(np.logical_and(gt, predict), axis=0)\n    fp = np.sum(np.logical_and(1-gt, predict), axis=0)\n    tn = np.sum(np.logical_and(1-gt, 1-predict), axis=0)\n    fn = np.sum(np.logical_and(gt, 1-predict), axis=0)\n    return np.stack([tp, fp, tn, fn], axis=0).astype(\"float\")\n\n\ndef label_accuracy_macro(gt, predict):\n    quantity = _label_quantity(gt, predict)\n    tp_tn = np.add(quantity[0], quantity[2])\n    tp_fp_tn_fn = np.sum(quantity, axis=0)\n    return np.mean((tp_tn + epsilon) / (tp_fp_tn_fn + epsilon))\n\n\ndef label_precision_macro(gt, predict):\n    quantity = _label_quantity(gt, predict)\n    tp = quantity[0]\n    tp_fp = np.add(quantity[0], quantity[1])\n    return np.mean((tp + epsilon) / (tp_fp + epsilon))\n\n\ndef label_recall_macro(gt, predict):\n    quantity = _label_quantity(gt, predict)\n    tp = quantity[0]\n    tp_fn = np.add(quantity[0], quantity[3])\n    return np.mean((tp + epsilon) / (tp_fn + epsilon))\n\n\ndef label_f1_macro(gt, predict):\n    p = label_precision_macro(gt, predict)\n    r = label_recall_macro(gt, predict)\n    return (2 * p * r) / (p + r + epsilon)\n\n\ndef label_accuracy_micro(gt, predict):\n    quantity = _label_quantity(gt, predict)\n    sum_tp, sum_fp, sum_tn, sum_fn = np.sum(quantity, axis=1)\n    return (sum_tp + sum_tn + epsilon) / (\n            sum_tp + sum_fp + sum_tn + sum_fn + epsilon)\n\n\ndef label_precision_micro(gt, predict):\n    quantity = _label_quantity(gt, predict)\n    sum_tp, sum_fp, sum_tn, sum_fn = np.sum(quantity, axis=1)\n    return (sum_tp + epsilon) / (sum_tp + sum_fp + epsilon)\n\n\ndef label_recall_micro(gt, predict):\n    quantity = _label_quantity(gt, predict)\n    sum_tp, sum_fp, sum_tn, sum_fn = np.sum(quantity, axis=1)\n    return (sum_tp + epsilon) / (sum_tp + sum_fn + epsilon)\n\n\ndef label_f1_micro(gt, predict):\n    p = label_precision_micro(gt, predict)\n    r = label_recall_micro(gt, predict)\n    return (2 * p * r) / (p + r + epsilon)\n\n\ndef single_label_accuracy(gt, predict):\n    quantity = _label_quantity(gt, predict)\n    tp_tn = np.add(quantity[0], quantity[2])\n    tp_fp_tn_fn = np.sum(quantity, axis=0)\n    return (tp_tn + epsilon) / (tp_fp_tn_fn + epsilon)\n\n\ndef single_label_precision(gt, predict):\n    quantity = _label_quantity(gt, predict)\n    tp = quantity[0]\n    tp_fp = np.add(quantity[0], quantity[1])\n    return (tp + epsilon) / (tp_fp + epsilon)\n\n\ndef single_label_recall(gt, predict):\n    quantity = _label_quantity(gt, predict)\n    tp = quantity[0]\n    tp_fn = np.add(quantity[0], quantity[3])\n    return (tp + epsilon) / (tp_fn + epsilon)\ndef write_metrics(gt, predict):\n    ex_subset_acc = example_subset_accuracy(gt, predict)\n    ex_acc = example_accuracy(gt, predict)\n    ex_precision = example_precision(gt, predict)\n    ex_recall = example_recall(gt, predict)\n    ex_f1 = compute_f1(ex_precision, ex_recall)\n\n    lab_acc_macro = label_accuracy_macro(gt, predict)\n    lab_precision_macro = label_precision_macro(gt, predict)\n    lab_recall_macro = label_recall_macro(gt, predict)\n    lab_f1_macro = compute_f1(lab_precision_macro, lab_recall_macro)\n\n    lab_acc_micro = label_accuracy_micro(gt, predict)\n    lab_precision_micro = label_precision_micro(gt, predict)\n    lab_recall_micro = label_recall_micro(gt, predict)\n    lab_f1_micro = compute_f1(lab_precision_micro, lab_recall_micro)\n\n    score_f1_macro = f1_score(gt, predict, average=\"macro\")\n   \n\n    score_f1_micro = f1_score(gt, predict, average=\"micro\")\n    \n\n    # hamming loss\n    h_loss = hamming_loss(gt, predict)\n    \n    \n    #zero_one_loss\n    z_o_loss = zero_one_loss(gt, predict)\n    \n    \n    mAP = average_precision_score(gt, predict)\n    \n    \n    OAA=accuracy_score(gt, predict)\n    \n    \n    Mconfusion_matri=multilabel_confusion_matrix(gt, predict)\n    \n    mul_matri=Mconfusion_matri.reshape(10,-1)\n    return  ex_subset_acc,OAA, ex_acc,ex_precision,ex_recall,ex_f1,lab_acc_macro,lab_precision_macro,lab_recall_macro,lab_f1_macro,lab_acc_micro,lab_precision_micro,lab_recall_micro,lab_f1_micro,score_f1_macro,score_f1_micro,h_loss,z_o_loss,mAP,mul_matri","metadata":{"execution":{"iopub.status.busy":"2023-03-31T04:04:42.964665Z","iopub.execute_input":"2023-03-31T04:04:42.965024Z","iopub.status.idle":"2023-03-31T04:04:42.997609Z","shell.execute_reply.started":"2023-03-31T04:04:42.964987Z","shell.execute_reply":"2023-03-31T04:04:42.996500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\n# def FocalLoss(y_pred, y_true, pos_weight, gamma):\n#     # y_pred is the logits before Sigmoid\n#     assert y_pred.shape == y_true.shape\n#     pt = torch.exp(-F.binary_cross_entropy_with_logits(y_pred, y_true, reduction='none')).detach()\n#     sample_weight = (1 - pt) ** gamma\n#     return F.binary_cross_entropy_with_logits(y_pred, y_true, weight=sample_weight, pos_weight=pos_weight)\n\nclass FocalLoss(nn.Module):\n    # Wraps focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5)\n    def __init__(self, loss_fcn, gamma=1.5, alpha=0.25):\n        super(FocalLoss, self).__init__()\n        self.loss_fcn = nn.BCEWithLogitsLoss()  # must be nn.BCEWithLogitsLoss()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = loss_fcn.reduction\n        self.loss_fcn.reduction = 'none'  # required to apply FL to each element\n        print(f'gamma_alpha',gamma, alpha)\n    def forward(self, pred_prob, true):\n        loss = self.loss_fcn(pred_prob, true)\n        # p_t = torch.exp(-loss)\n        # loss *= self.alpha * (1.000001 - p_t) ** self.gamma  # non-zero power for gradient stability\n        # TF implementation https://github.com/tensorflow/addons/blob/v0.7.1/tensorflow_addons/losses/focal_loss.py\n        #pred_prob = torch.sigmoid(pred)  # prob from logits\n        p_t = true * pred_prob + (1 - true) * (1 - pred_prob)\n        alpha_factor = true * self.alpha + (1 - true) * (1 - self.alpha)\n        modulating_factor = (1.0 - p_t) ** self.gamma\n        loss *= alpha_factor * modulating_factor\n\n        if self.reduction == 'mean':\n            return loss.mean()\n        elif self.reduction == 'sum':\n            return loss.sum()\n        else:  # 'none'\n            return loss\n\nclass AsymmetricLoss(nn.Module):\n    def __init__(self, gamma_neg=4, gamma_pos=1, clip=0.05, eps=1e-8, disable_torch_grad_focal_loss=True):\n        super(AsymmetricLoss, self).__init__()\n        self.gamma_neg = gamma_neg\n        print(f'gamma_neg',gamma_neg, gamma_pos)\n        self.gamma_pos = gamma_pos\n        self.clip = clip\n        self.disable_torch_grad_focal_loss = disable_torch_grad_focal_loss\n        self.eps = eps\n\n    def forward(self, x_sigmoid, y):\n        \"\"\"\"\n        Parameters\n        ----------\n        x: input logits\n        y: targets (multi-label binarized vector)\n        \"\"\"\n        # Calculating Probabilities\n        #x_sigmoid = torch.sigmoid(x)\n        xs_pos = x_sigmoid\n        xs_neg = 1 - x_sigmoid\n\n        # Asymmetric Clipping\n        if self.clip is not None and self.clip > 0:\n            xs_neg = (xs_neg+self.clip).clamp(max=1)\n\n        # Basic CE calculation\n        los_pos = y * torch.log(xs_pos.clamp(min=self.eps))\n        los_neg = (1 - y) * torch.log(xs_neg.clamp(min=self.eps))\n        loss = los_pos + los_neg\n\n        # Asymmetric Focusing\n        if self.gamma_neg > 0 or self.gamma_pos > 0:\n            if self.disable_torch_grad_focal_loss:\n                torch.set_grad_enabled(False)\n            pt0 = xs_pos * y\n            pt1 = xs_neg * (1 - y)  # pt = p if t > 0 else 1-p\n            pt = pt0 + pt1\n            one_sided_gamma = self.gamma_pos * y + self.gamma_neg * (1 - y)\n            one_sided_w = torch.pow(1 - pt, one_sided_gamma)\n            if self.disable_torch_grad_focal_loss:\n                torch.set_grad_enabled(True)\n            loss *= one_sided_w\n\n        return -loss.sum()\nclass Asy1(nn.Module):\n    def __init__(self, alpha=0.25,  clip=0.05, eps=1e-8, disable_torch_grad_focal_loss=True):\n        super(Asy1,self).__init__()\n        self.alpha = alpha\n        self.clip = clip\n        print(f'alpha_clip',alpha,clip)\n        self.disable_torch_grad_focal_loss = disable_torch_grad_focal_loss\n        self.eps = eps\n\n    def forward(self, x_sigmoid, y):\n        \"\"\"\"\n        Parameters\n        ----------\n        x: input logits\n        y: targets (multi-label binarized vector)\n        \"\"\"\n        # Calculating Probabilities\n        #x_sigmoid = torch.sigmoid(x)\n        xs_pos = x_sigmoid\n        xs_neg = 1 - x_sigmoid\n\n        # Asymmetric Clipping #添加一个阈值\n        if self.clip is not None and self.clip > 0:\n            xs_neg = (xs_neg+self.clip).clamp(max=1)\n\n        # Basic CE calculation  基础的BCE计算\n        los_pos = y * torch.log(xs_pos.clamp(min=self.eps))\n        los_neg = (1 - y) * torch.log(xs_neg.clamp(min=self.eps))\n        loss = los_pos + los_neg\n\n        # Asymmetric Focusing\n        if self.alpha > 0:\n            if self.disable_torch_grad_focal_loss:\n                torch.set_grad_enabled(False)\n            one_sided_alpha = self.alpha * y + (1-self.alpha) * (1 - y)\n            if self.disable_torch_grad_focal_loss:\n                torch.set_grad_enabled(True)\n            loss *= one_sided_alpha\n\n        return -loss.sum()\n\nclass AsymmetricLossOptimized(nn.Module):\n    ''' Notice - optimized version, minimizes memory allocation and gpu uploading,\n    favors inplace operations'''\n\n    def __init__(self, gamma_neg=4, gamma_pos=1, clip=0.05, eps=1e-8, disable_torch_grad_focal_loss=False):\n        super(AsymmetricLossOptimized, self).__init__()\n\n        self.gamma_neg = gamma_neg\n        self.gamma_pos = gamma_pos\n        self.clip = clip\n        self.disable_torch_grad_focal_loss = disable_torch_grad_focal_loss\n        self.eps = eps\n\n        # prevent memory allocation and gpu uploading every iteration, and encourages inplace operations\n        self.targets = self.anti_targets = self.xs_pos = self.xs_neg = self.asymmetric_w = self.loss = None\n\n    def forward(self, x, y):\n        \"\"\"\"\n        Parameters\n        ----------\n        x: input logits\n        y: targets (multi-label binarized vector)\n        \"\"\"\n\n        self.targets = y\n        self.anti_targets = 1 - y\n\n        # Calculating Probabilities\n        #self.xs_pos = torch.sigmoid(x)\n        self.xs_pos = x\n        self.xs_neg = 1.0 - self.xs_pos\n\n        # Asymmetric Clipping\n        if self.clip is not None and self.clip > 0:\n            self.xs_neg.add_(self.clip).clamp_(max=1)\n\n        # Basic CE calculation\n        self.loss = self.targets * torch.log(self.xs_pos.clamp(min=self.eps))\n        self.loss.add_(self.anti_targets * torch.log(self.xs_neg.clamp(min=self.eps)))\n\n        # Asymmetric Focusing\n        if self.gamma_neg > 0 or self.gamma_pos > 0:\n            if self.disable_torch_grad_focal_loss:\n                torch.set_grad_enabled(False)\n            self.xs_pos = self.xs_pos * self.targets\n            self.xs_neg = self.xs_neg * self.anti_targets\n            self.asymmetric_w = torch.pow(1 - self.xs_pos - self.xs_neg,\n                                          self.gamma_pos * self.targets + self.gamma_neg * self.anti_targets)\n            if self.disable_torch_grad_focal_loss:\n                torch.set_grad_enabled(True)\n            self.loss *= self.asymmetric_w\n\n        return -self.loss.sum()\n\n\nclass ASLSingleLabel(nn.Module):\n    '''\n    This loss is intended for single-label classification problems\n    '''\n    def __init__(self, gamma_pos=0, gamma_neg=4, eps: float = 0.1, reduction='mean'):\n        super(ASLSingleLabel, self).__init__()\n\n        self.eps = eps\n        self.logsoftmax = nn.LogSoftmax(dim=-1)\n        self.targets_classes = []\n        self.gamma_pos = gamma_pos\n        self.gamma_neg = gamma_neg\n        self.reduction = reduction\n\n    def forward(self, inputs, target):\n        '''\n        \"input\" dimensions: - (batch_size,number_classes)\n        \"target\" dimensions: - (batch_size)\n        '''\n        num_classes = inputs.size()[-1]\n        log_preds = self.logsoftmax(inputs)\n        self.targets_classes = torch.zeros_like(inputs).scatter_(1, target.long().unsqueeze(1), 1)\n\n        # ASL weights\n        targets = self.targets_classes\n        anti_targets = 1 - targets\n        xs_pos = torch.exp(log_preds)\n        xs_neg = 1 - xs_pos\n        xs_pos = xs_pos * targets\n        xs_neg = xs_neg * anti_targets\n        asymmetric_w = torch.pow(1 - xs_pos - xs_neg,\n                                 self.gamma_pos * targets + self.gamma_neg * anti_targets)\n        log_preds = log_preds * asymmetric_w\n\n        if self.eps > 0:  # label smoothing\n            self.targets_classes = self.targets_classes.mul(1 - self.eps).add(self.eps / num_classes)\n\n        # loss calculation\n        loss = - self.targets_classes.mul(log_preds)\n\n        loss = loss.sum(dim=-1)\n        if self.reduction == 'mean':\n            loss = loss.mean()\n\n        return loss\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T04:04:43.001686Z","iopub.execute_input":"2023-03-31T04:04:43.002095Z","iopub.status.idle":"2023-03-31T04:04:43.035238Z","shell.execute_reply.started":"2023-03-31T04:04:43.002067Z","shell.execute_reply":"2023-03-31T04:04:43.034237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Thu Feb 23 16:08:30 2023\n\n@author: lisha\n\"\"\"\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd\n\n\n\n\n#3个融合\nclass my_Data_Set3(nn.Module):\n    \n    def __init__(self, num_fea,m,infor1,infor2,infor3,lbp):\n        super(my_Data_Set3, self).__init__()\n        # 打开存储图像名与标签的txt文件\n        self.images = infor1[:,1] #图像名\n        self.feature1=infor1[:,2:m-5]\n        self.feature2=infor2[:,2:m-5]\n        self.feature3=infor3[:,2:m-5]\n        self.lbp=lbp\n        self.labels = infor1[:,m-5:]\n        self.num_fea=num_fea\n        print('3个融合')\n    def __getitem__(self, item):\n        # 获取图像名和标签\n        imageName = self.images[item]\n        label = self.labels[item]\n       # 读入图像信息\n        feature1=self.feature1[item]\n        feature2=self.feature2[item]\n        feature3=self.feature3[item]\n        lbp=self.lbp[item]\n        feature1= pd.to_numeric(feature1) #object格式转为数值格式\n        feature2= pd.to_numeric(feature2)\n        feature3= pd.to_numeric(feature3)\n        label = pd.to_numeric(label)\n        lbp= pd.to_numeric(lbp)\n        feature_=np.append(feature1,feature2)\n        feature_=np.append(feature_,feature3)\n        feature_=np.matrix(feature_)\n        lbp=np.matrix(lbp)\n       #格式的转换\n        lbp=lbp.reshape(1,-1)\n        feature=feature_.reshape(self.num_fea,-1)\n       # 需要将标签转换为float类型，BCELoss只接受float类型\n        label = torch.FloatTensor(label)\n        feature= torch.FloatTensor(feature)\n        lbp= torch.FloatTensor(lbp)\n       # print(lbp.shape)\n       # print(feature.shape)\n       # print(label.shape)\n        return feature,lbp,label\n \n    # 重写这个函数，来看数据集中含有多少数据\n    def __len__(self):\n        return len(self.images)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T04:04:43.038828Z","iopub.execute_input":"2023-03-31T04:04:43.039138Z","iopub.status.idle":"2023-03-31T04:04:43.053500Z","shell.execute_reply.started":"2023-03-31T04:04:43.039099Z","shell.execute_reply":"2023-03-31T04:04:43.052475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n#数据集整理\nalexnet128_train= pd.read_csv(\"/kaggle/input/newdata0330/new_alexnet128_train_all.csv\")\nalexnet128_train=np.array(alexnet128_train) \nalexnet128_test= pd.read_csv(\"/kaggle/input/newdata0330/new_alexnet128_test_all.csv\")\nalexnet128_test=np.array(alexnet128_test) \n\ndensent128_train= pd.read_csv(\"/kaggle/input/newdata0330/new_densnet128_train_all.csv\")\ndensent128_train=np.array(densent128_train) \ndensent128_test= pd.read_csv(\"/kaggle/input/newdata0330/new_densnet128_test_all.csv\")\ndensent128_test=np.array(densent128_test) \n\nvgg128_train= pd.read_csv(\"/kaggle/input/newdata0330/new_vgg128_train_all.csv\")\nvgg128_train=np.array(vgg128_train) \nvgg128_test= pd.read_csv(\"/kaggle/input/newdata0330/new_vgg128_test_all.csv\")\nvgg128_test=np.array(vgg128_test) \n\nresnet128_train= pd.read_csv(\"/kaggle/input/newdata0330/new_resnet128_train_all.csv\")\nresnet128_train=np.array(resnet128_train) \nresnet128_test= pd.read_csv(\"/kaggle/input/newdata0330/new_resnet128_test_all.csv\")\nresnet128_test=np.array(resnet128_test)\n\n\nlbp_train= pd.read_csv(\"/kaggle/input/newdata0330/new_lbp_train.CSV\")\n#lbp_train=pd.DataFrame(lbp_train,dtype=np.float)；\nlbp_test= pd.read_csv(\"/kaggle/input/newdata0330/new_lbp_test.CSV\")\nlbp_train=np.array(lbp_train)\nlbp_test=np.array(lbp_test)\n\nm=resnet128_train.shape[1]\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nnum_class=5\n# Transformer Parameters\nd_model =128 # Embedding Size,512-1024,128-512\nq_model=lbp_test.shape[1]\nd_ff = 1024# FeedForward dimension\nn_layers = 4  # number of Encoder of Decoder Layer\nn_heads = 4  # number of heads in Multi-Head Attention\nd_k = d_v =int(d_model/n_heads) # dimension of K(=Q), V\nbatch_size=50\n#一些超参数的设计\na=4   #控制不对称的顺势函数，gamma_neg\nb=1  #控制不对称的顺势函数，gamma_pos\n\n\n# 定义自己数据集的数据读入类\n#order=[resnet,densent,vgg,alexnet]\norder1=1\norder2=1\norder3=1\norder4=0\nnum_fea=3\ntrain_Data = my_Data_Set3(num_fea,m,resnet128_train,densent128_train,alexnet128_train,lbp_train)\ntest_Data =my_Data_Set3(num_fea,m,resnet128_test,densent128_test,alexnet128_test,lbp_test)\n\n#train_Data = my_Data_Set(vgg128_train,alexnet128_train,lbp_train)\n# 读取数据集大小\ndataset_sizes = {'train': train_Data.__len__(), 'test': test_Data.__len__()}\ntrain_DataLoader = DataLoader(train_Data, batch_size, shuffle=True)\ntest_DataLoader = DataLoader(test_Data, batch_size, shuffle=True)\ndataloaders = {'train':train_DataLoader, 'test':test_DataLoader}","metadata":{"execution":{"iopub.status.busy":"2023-03-31T04:04:43.055066Z","iopub.execute_input":"2023-03-31T04:04:43.055511Z","iopub.status.idle":"2023-03-31T04:04:44.950974Z","shell.execute_reply.started":"2023-03-31T04:04:43.055475Z","shell.execute_reply":"2023-03-31T04:04:44.949722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndef train_model(model, parameters, dtype, device,num_epochs):\n    torch.cuda.manual_seed_all(1)\n    since = time.time()\n    #active_fun = nn.Sigmoid()\n    #best_model_wts = copy.deepcopy(model.state_dict())\n    best_model_wts=[]\n    best_acc = 0.0\n    train_acc=0.0\n    num_epoch=0\n    train_pre_best=[]\n    train_output_best=[]\n    train_label_best=[]\n    test_pre_best=[]\n    test_output_best=[]\n    test_label_best=[]\n    #optimizer = optim.SGD(net.parameters(), # or any optimizer you prefer \n  #                       lr=parameters.get(\"lr\", 0.001), # 0.001 is used if no lr is specified\n  #                       momentum=parameters.get(\"momentum\", 0.9)\n  # )\n    alpha=parameters.get(\"alpha\", 0.05)/20\n    clip=parameters.get(\"clip\", 0.01)/100\n    lamda=parameters.get(\"lamda\", 0.15)/100\n    criterion = Asy1(alpha,clip).to(device)\n    #criterion = Asy1(alpha=aa, clip=c)\n    optimizer= optim.SGD(model.parameters(), lr=0.001, momentum=0.4)\n    #optimizer=optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n    scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n    for epoch in range(num_epochs):\n        train_pre=[]\n        train_output=[]\n        train_label=[]\n        test_pre=[]\n        test_output=[]\n        test_label=[]\n        #ytesttmp=np.ones((1,num_class))*0.5\n        train_pre=np.ones((1,num_class))*0.5\n        train_output=np.ones((1,num_class))*0.5\n        train_label=np.ones((1,num_class))*0.5\n        test_pre=np.ones((1,num_class))*0.5\n        test_output=np.ones((1,num_class))*0.5\n        test_label=np.ones((1,num_class))*0.5\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print('-' * 10)\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'test']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode#模型评估\n            running_loss = 0.0\n            running_corrects = 0\n            # Iterate over data.\n            for deepinputs,trainputs,labels in dataloaders[phase]:\n                deepinputs = deepinputs.to(device)\n                trainputs = trainputs.to(device)\n                labels = labels.to(device)\n                #print('deepinputs',deepinputs.is_cuda)\n                #print('输入trainputs：',trainputs.size())\n                #print('输入deepinputs：',deepinputs.size())\n                #print('输入labels：',labels.size())\n                # zero the parameter gradients\n                optimizer.zero_grad()\n                # forward\n                # track history if only in train\n                #model.to(device)\n                #print('model',model.is_cuda)\n                with torch.set_grad_enabled(phase == 'train'):\n                    trainputs.to(device)\n                    deepinputs.to(device)\n                    #print('trainputs',trainputs.is_cuda)\n                    model.to(device)\n                    outputs,enc_self_attns= model(trainputs,deepinputs)\n                    #这一条命令有问题\n                    #print('outputs',outputs.is_cuda)\n                    #print('输出outputs：',outputs.size())\n                    #print(outputs.size())\n                    outputs = outputs.to(device)\n                    loss = criterion(outputs, labels)\n                    # batch_size1=inputs.size(0)\n                    # outputs=outputs.view(batch_size1,num_class)\n                    preds=preclass(outputs,lamda)\n                    #loss = criterion(outputs, labels)\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                    \n                # statistics\n                running_loss += loss.item() * deepinputs.size(0)\n                #running_corrects += torch.sum(preds == labels.data)\n                running_corrects += newacc(preds,labels.data)\n                #print('running_corrects',running_corrects)\n                if phase == 'train':\n                    #print('preds1',preds.is_cuda)\n                    preds=preds.detach().cpu().numpy()\n                    #print('preds2',preds.is_cuda)\n                    outputs=outputs.detach().cpu().numpy()\n                    labels=labels.detach().cpu().numpy()\n                    train_pre=np.vstack((train_pre,preds))\n                    train_output=np.vstack((train_output,outputs))\n                    train_label=np.vstack((train_label,labels))\n                    #train_pre=train_pre.to(device)\n\n                if phase == 'test':\n                    preds=preds.detach().cpu().numpy()\n                    outputs=outputs.detach().cpu().numpy()\n                    labels=labels.detach().cpu().numpy()\n                    test_pre=np.vstack((test_pre,preds))\n                    test_output=np.vstack((test_output,outputs))\n                    test_label=np.vstack((test_label,labels))\n            if phase == 'train':\n                scheduler.step()\n            epoch_loss = running_loss / dataset_sizes[phase]\n            #torch.sum(preds == labels.data)\n            #epoch_acc = running_corrects.double() / dataset_sizes[phase]\n            if phase == 'train':\n                epoch_train_acc = running_corrects / dataset_sizes[phase]\n                epoch_acc=epoch_train_acc\n            if phase == 'test':\n                epoch_test_acc = running_corrects / dataset_sizes[phase]\n                epoch_acc=epoch_test_acc\n            print('running_corrects',running_corrects)\n            print(f'dataset_sizes{phase}',dataset_sizes[phase])\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n            # deep copy the model,val或者train\n            \n            if phase == 'test' and epoch_test_acc>= best_acc:\n                best_acc = epoch_test_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n                best_epoch=num_epoch\n                train_acc = epoch_train_acc\n                train_pre_best=train_pre\n                train_output_best=train_output\n                train_label_best=train_label\n                test_pre_best=test_pre\n                test_output_best=test_output\n                test_label_best=test_label\n            \n                \n        print()\n        num_epoch=num_epoch+1\n    time_elapsed = time.time() - since\n    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'train Acc: {train_acc:4f}')\n    print(f'Best test Acc: {best_acc:4f}')\n    print(f'best_epoch: {best_epoch:4f}')\n    \n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    \n    return alpha,clip,lamda,model,train_pre_best,train_output_best,train_label_best,test_pre_best,test_output_best,test_label_best\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T04:04:44.953290Z","iopub.execute_input":"2023-03-31T04:04:44.954025Z","iopub.status.idle":"2023-03-31T04:04:44.980174Z","shell.execute_reply.started":"2023-03-31T04:04:44.953983Z","shell.execute_reply":"2023-03-31T04:04:44.979006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a_result_ASL_=[]\n\ndef init_net(parameterization):\n    cudnn.benchmark = False            # if benchmark=True, deterministic will be False\n    cudnn.deterministic = True\n    seed=1\n    torch.manual_seed(seed)            # 为CPU设置随机种子\n    torch.cuda.manual_seed(seed)       # 为当前GPU设置随机种子\n    torch.cuda.manual_seed_all(seed)   # 为所有GPU设置随机种子\n    random.seed(seed)\n    np.random.seed(seed)\n    model=Encoder() #\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    model=model.to(device)\n\n    # The depth of unfreezing is also a hyperparamete\n    return model # return untrained model\n#最后，我们需要一个train_evaluate()函数，该函数在每次运行时都会被贝叶斯优化器调用。\n# 优化器在parameterization化中生成一组新的超parameterization ，将其传递给此函数，\n#然后分析返回的评估结果。\na_result_ASL_=[]\ndef train_evaluate(parameterization):\n    # constructing a new training data loader allows us to tune the batch size\n    # Get neural net\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    untrained_net = init_net(parameterization) \n    untrained_net.to(device)\n    # train\n    #trained_net = train_model(net=untrained_net, train_loader=train_loader, \n                            # parameters=parameterization, dtype=dtype, device=device)\n    alpha,clip,lamda,trained_net,train_pre,train_output,train_label,test_pre,test_output,test_label = train_model(untrained_net, parameters=parameterization, dtype=dtype, device=device,num_epochs=40)\n    \n    # return the accuracy of the model as it was trained in this run\n    #return evaluate(\n    #     net=trained_net,\n    #     data_loader=testloader,\n    #     dtype=dtype,\n    #     device=device,\n    # )\n    ex_subset_acc,OAA,ex_acc,ex_precision,ex_recall,ex_f1,lab_acc_macro,lab_precision_macro,lab_recall_macro,lab_f1_macro,lab_acc_micro,lab_precision_micro,lab_recall_micro,lab_f1_micro,score_f1_macro,score_f1_micro,h_loss,z_o_loss,mAP,mul_matri=write_metrics(test_label[1:,:],test_pre[1:,:])\n    a_result_ASL=[alpha,clip,lamda,ex_subset_acc, OAA,ex_acc,ex_recall,ex_f1,lab_acc_macro,lab_precision_macro,lab_recall_macro,lab_f1_macro,lab_acc_micro,lab_precision_micro,lab_recall_micro,lab_f1_micro,score_f1_macro,score_f1_micro,h_loss,z_o_loss,mAP]\n    a_result_ASL_.append(a_result_ASL)\n    a_result_ASL_1=pd.DataFrame(a_result_ASL_)\n    a_result_ASL_1.to_csv('/kaggle/working/result_SGD128_3_2.csv')\n    #ex_subset_acc.to(device)\n    #print(ex_subset_acc)\n    return ex_subset_acc\n# model,train_pre_best,train_output_best,train_label_best,test_pre_best,test_output_best,test_label_best\n\n#dtype = torch.float\n#优化操作\n#torch.cuda.set_device(0) #this is sometimes necessary for me\ndtype = torch.int\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n \nbest_parameters, values, experiment, model = optimize(\n    parameters=[\n        {\"name\": \"alpha\", \"type\": \"range\", \"bounds\": [4, 14],},\n        {\"name\": \"clip\", \"type\": \"range\", \"bounds\": [1, 10]},\n        {\"name\": \"lamda\", \"type\": \"range\", \"bounds\": [1, 20]},\n        #{\"name\": \"max_epoch\", \"type\": \"range\", \"bounds\": [1, 30]},\n        #{\"name\": \"stepsize\", \"type\": \"range\", \"bounds\": [20, 40]},        \n    ],\n  \n    evaluation_function=train_evaluate,\n    objective_name='Subset_Accuracy',\n)\n#print(parameters.is_cuda)\nprint(best_parameters)\nmeans, covariances = values\nprint(means)\nprint(covariances)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T04:04:44.981981Z","iopub.execute_input":"2023-03-31T04:04:44.982443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_objectives = np.array([[trial.objective_mean*100 for trial in experiment.trials.values()]])\n \nbest_objective_plot = optimization_trace_single_method(\n    y=np.maximum.accumulate(best_objectives, axis=1),\n    #title=\"Model performance vs. # of iterations\",\n    ylabel=\"Subset_Accuracy %\",\n)\nrender(best_objective_plot)\n#plt.savefig(\"best_objective_plot.jpg\")\nrender(plot_contour(model=model, param_x='alpha', param_y='clip', metric_name='Subset_Accuracy'))\n#plt.savefig(\"performance.jpg\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.savefig(\"best_objective_plot.jpg\")\nrender(plot_contour(model=model, param_x='alpha', param_y='clip', metric_name='Subset_Accuracy'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}